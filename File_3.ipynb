{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kii72W39b51h"
      },
      "source": [
        "\n",
        "Build an Artificial Neural Network by implementing the Backpropagation algorithm and test the same using appropriate data sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8LMAJjJ8yl-C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# Two inputs (sleep,study)\n",
        "x=np.array(([2,9],[1,5],[3,6]),dtype=float)\n",
        "# One output (expected % in the exam)\n",
        "y=np.array(([92],[86],[89]),dtype=float)\n",
        "# maximum of x array longitudinally(normalize the data to scale the values)\n",
        "X=x/np.amax(x,axis=0)\n",
        "Y=y/100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2N3q-8waVIP"
      },
      "source": [
        "Variable initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AoMe5XSvdQnB"
      },
      "outputs": [],
      "source": [
        "#Variable initialization\n",
        "\n",
        "# setting training iterations\n",
        "epoch =5000\n",
        "# setting learning iterations\n",
        "lr=0.1\n",
        "inputlayer_neurons=2      # number of feature dataset\n",
        "hiddenlayer_neurons=3     # number of hidden layer neurons\n",
        "output_neurons=1          # number of neurons at output layer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtW4Lr3LaRxL"
      },
      "source": [
        "weight abd bias initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QuNwExBwgdNJ"
      },
      "outputs": [],
      "source": [
        "# weight abd bias initialization\n",
        "\n",
        "# weight of the link from input layer to hidden layer\n",
        "wh=np.random.uniform(size=(inputlayer_neurons,hiddenlayer_neurons))\n",
        "# bias of the link from input layer to hidden layer\n",
        "bh=np.random.uniform(size=(1,hiddenlayer_neurons))\n",
        "# weight of the link from hidden layer to output layer\n",
        "wout=np.random.uniform(size=(hiddenlayer_neurons,output_neurons))\n",
        "# bias of the link from hidden layer to output layer\n",
        "bout=np.random.uniform(size=(1,output_neurons))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSCKkv6jaenj"
      },
      "source": [
        "Sigmoid Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SQGzpL9bhkaP"
      },
      "outputs": [],
      "source": [
        "# Sigmoid Function\n",
        "def sigmoid (x):\n",
        "  return 1/(1+np.exp(-x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL7ZHTloah60"
      },
      "source": [
        "Derivative of sigmoid function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "b3GTihoViR_s"
      },
      "outputs": [],
      "source": [
        "# derivative of sigmoid function\n",
        "# identify in which direction and how much update is required while updating curve\n",
        "def derivatives_sigmoid(x):\n",
        "  return x * (1-x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "e1NJ7HfDjchU"
      },
      "outputs": [],
      "source": [
        "# draws a random range of numbers uniformaly of dis x*y\n",
        "for i in range(epoch):\n",
        "\n",
        "  # Forward Propogation\n",
        "\n",
        "  # hinput=X*wh+bh\n",
        "  hinput_1=np.dot(X,wh)\n",
        "  hinput=hinput_1+bh\n",
        "  # sigmoid function on hinput\n",
        "  hlayer_act=sigmoid(hinput)\n",
        "  # # output=X*wh+bh\n",
        "  out_input1=np.dot(hlayer_act,wout)\n",
        "  out_input=out_input1+bout\n",
        "  output=sigmoid(out_input)\n",
        "\n",
        "  # Backpropogation\n",
        "  # errors are identified at two layers 1)output layer 2) hidden layer\n",
        "\n",
        "  # How much output layer weight computed to that error\n",
        "  EO=Y-output\n",
        "  outgrad=derivatives_sigmoid(output)\n",
        "  d_output= EO* outgrad\n",
        "\n",
        "  EH = d_output.dot(wout.T)\n",
        "  # How much hidden layer weight computed to that error\n",
        "  hiddengrad=derivatives_sigmoid(hlayer_act)\n",
        "  d_hiddenlayer= EH * hiddenlayer_neurons\n",
        "\n",
        "  # dotproduct of nextlayererror and currentlayer\n",
        "  # update the output layer weights and the hidden layer weights\n",
        "  wout += hlayer_act.T.dot(d_output) * lr\n",
        "  wh += X.T.dot(d_hiddenlayer)*lr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpZxvdyrwZb3",
        "outputId": "9cb61056-60ad-4656-8ba3-95b6675249d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : \n",
            "[[0.66666667 1.        ]\n",
            " [0.33333333 0.55555556]\n",
            " [1.         0.66666667]]\n",
            "Output : \n",
            "[[0.92]\n",
            " [0.86]\n",
            " [0.89]]\n",
            "Predicted Output : \n",
            "[[0.89493456]\n",
            " [0.88222263]\n",
            " [0.89370445]]\n"
          ]
        }
      ],
      "source": [
        "print('Input : \\n' + str(X))\n",
        "print('Output : \\n' + str(Y))\n",
        "print('Predicted Output : \\n' + str(output))\n"
      ]
    }
  ]
}